{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7f114c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c00cc87",
   "metadata": {},
   "source": [
    "### Домашнее задание 1, часть 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee442b9",
   "metadata": {},
   "source": [
    "Классификация изображений (пролив/не пролив)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f3cda6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'dataset' not in os.listdir():\n",
    "    with zipfile.ZipFile('dataset.zip') as zipfile:\n",
    "        zipfile.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec6dd29",
   "metadata": {},
   "source": [
    "#### Загрузка данных для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a637fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None, target_size=(28, 28)):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_size = target_size\n",
    "        self.image_files = [f for f in os.listdir(img_dir) if f.endswith(('jpg',))]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.image_files[idx])\n",
    "        image = Image.open(img_path)\n",
    "        image = transforms.functional.resize(image, self.target_size)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be30ea6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_transform = transforms.ToTensor()\n",
    "train_dataset = ImageDataset(\n",
    "    img_dir='dataset/train',\n",
    "    transform=tensor_transform,\n",
    "    target_size=(28, 28)\n",
    ")\n",
    "\n",
    "test_positive_dataset = ImageDataset(\n",
    "    img_dir='dataset/proliv',\n",
    "    transform=tensor_transform,\n",
    "    target_size=(28, 28)\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_positive_loader = torch.utils.data.DataLoader(test_positive_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1cff08",
   "metadata": {},
   "source": [
    "#### Класс модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "24c49c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28 * 28 * 3, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 36),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(36, 18),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(18, 9)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(9, 18),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(18, 36),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(36, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 28 * 28 * 3),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d5aab0",
   "metadata": {},
   "source": [
    "#### Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d552ea4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_autoencoder(autoencoder, train_loader, num_epochs):\n",
    "    optimizer = torch.optim.Adam(autoencoder.parameters())\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for data in train_loader:\n",
    "            data = data.view(data.size(0), -1)\n",
    "            \n",
    "            outputs = autoencoder(data)\n",
    "            loss = criterion(outputs, data)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c57d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.0017\n",
      "Epoch [2/10], Loss: 0.0011\n",
      "Epoch [3/10], Loss: 0.0009\n",
      "Epoch [4/10], Loss: 0.0012\n",
      "Epoch [5/10], Loss: 0.0009\n",
      "Epoch [6/10], Loss: 0.0009\n",
      "Epoch [7/10], Loss: 0.0008\n",
      "Epoch [8/10], Loss: 0.0010\n",
      "Epoch [9/10], Loss: 0.0011\n",
      "Epoch [10/10], Loss: 0.0012\n"
     ]
    }
   ],
   "source": [
    "autoencoder = AutoEncoder()\n",
    "train_autoencoder(autoencoder, train_loader, num_epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cda305b",
   "metadata": {},
   "source": [
    "#### Оценка на изображениях с проливами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2a758f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_threshold(autoencoder, train_loader, test_loader):\n",
    "\n",
    "    autoencoder.eval()\n",
    "    criterion = torch.nn.MSELoss(reduction='none')\n",
    "    \n",
    "    train_losses = []\n",
    "    with torch.no_grad():\n",
    "        for data in train_loader:\n",
    "            data = data.view(data.size(0), -1)\n",
    "            outputs = autoencoder(data)\n",
    "            loss = criterion(outputs, data)\n",
    "            train_losses.extend(loss.mean(dim=1).tolist())\n",
    "\n",
    "    test_losses = []\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            data = data.view(data.size(0), -1)\n",
    "            outputs = autoencoder(data)\n",
    "            loss = criterion(outputs, data)\n",
    "            test_losses.extend(loss.mean(dim=1).tolist())\n",
    "    \n",
    "    threshold = np.mean(train_losses) + 3 * np.std(train_losses)\n",
    "\n",
    "    true_positives = sum(l > threshold for l in test_losses)\n",
    "    false_negatives = len(test_losses) - true_positives\n",
    "    false_positives = sum(l > threshold for l in train_losses)\n",
    "    \n",
    "    print(f\"Suggested Threshold: {threshold:.4f}\")\n",
    "    print(f'False negatives: {false_negatives}/{len(test_losses)}')\n",
    "    print(f\"Positive samples detected as anomalies: {true_positives}/{len(test_losses)}\")\n",
    "    print(f\"Negative samples detected as anomalies: {false_positives}/{len(train_losses)}\")\n",
    "    \n",
    "    return threshold, train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8a18194a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested Threshold: 0.0030\n",
      "False negatives: 0/154\n",
      "Positive samples detected as anomalies: 154/154\n",
      "Negative samples detected as anomalies: 108/10000\n"
     ]
    }
   ],
   "source": [
    "threshold, train_losses, test_losses = evaluate_threshold(\n",
    "    autoencoder, \n",
    "    train_loader,\n",
    "    test_positive_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea1b0de",
   "metadata": {},
   "source": [
    "#### Оценка на тестовом датасете с отметками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "43e4e848",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabeledImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, label_dict, transform=None, target_size=(28, 28)):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_size = target_size\n",
    "        self.label_dict = label_dict\n",
    "        self.image_files = [f for f in os.listdir(img_dir) if f.endswith(('jpg', 'png')) and f in label_dict]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.image_files[idx])\n",
    "        image = Image.open(img_path)\n",
    "        image = transforms.functional.resize(image, self.target_size)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        label = self.label_dict[self.image_files[idx]]\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bb389f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(label_file):\n",
    "    labels = {}\n",
    "    with open(label_file, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) == 2:\n",
    "                filename, label = parts\n",
    "                labels[filename] = int(label)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9eb760cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(autoencoder, test_img_dir, label_file, threshold):\n",
    "\n",
    "    autoencoder.eval()\n",
    "    transform = transforms.ToTensor()\n",
    "\n",
    "    label_dict = load_labels(label_file)\n",
    "    \n",
    "    test_dataset = LabeledImageDataset(\n",
    "        img_dir=test_img_dir,\n",
    "        label_dict=label_dict,\n",
    "        transform=transform,\n",
    "        target_size=(28, 28)\n",
    "    )\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    criterion = torch.nn.MSELoss(reduction='none')\n",
    "    \n",
    "    true_positives = 0\n",
    "    true_negatives = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, labels in test_loader:\n",
    "            data = data.view(data.size(0), -1)\n",
    "            outputs = autoencoder(data)\n",
    "            loss = criterion(outputs, data).mean(dim=1)\n",
    "            \n",
    "            predictions = (loss > threshold).cpu().numpy()\n",
    "            \n",
    "            for pred, label in zip(predictions, labels):\n",
    "                if label == 1:\n",
    "                    if pred:\n",
    "                        true_positives += 1\n",
    "                    else:\n",
    "                        false_negatives += 1\n",
    "                else:\n",
    "                    if not pred:\n",
    "                        true_negatives += 1\n",
    "                    else:\n",
    "                        false_positives += 1\n",
    "    \n",
    "    total_positives = true_positives + false_negatives\n",
    "    total_negatives = true_negatives + false_positives\n",
    "    \n",
    "    tpr = true_positives / total_positives if total_positives > 0 else 0\n",
    "    tnr = true_negatives / total_negatives if total_negatives > 0 else 0\n",
    "    \n",
    "    print(f\"Threshold: {threshold:.4f}\")\n",
    "    print(f\"True Positives (TP): {true_positives}\")\n",
    "    print(f\"False Negatives (FN): {false_negatives}\")\n",
    "    print(f\"True Negatives (TN): {true_negatives}\")\n",
    "    print(f\"False Positives (FP): {false_positives}\")\n",
    "    print(f\"True Positive Rate: {tpr:.4f}\")\n",
    "    print(f\"True Negative Rate: {tnr:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'TP': true_positives,\n",
    "        'FN': false_negatives,\n",
    "        'TN': true_negatives,\n",
    "        'FP': false_positives,\n",
    "        'TPR': tpr,\n",
    "        'TNR': tnr,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "55db2994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.0030\n",
      "True Positives (TP): 100\n",
      "False Negatives (FN): 29\n",
      "True Negatives (TN): 3067\n",
      "False Positives (FP): 598\n",
      "True Positive Rate: 0.7752\n",
      "True Negative Rate: 0.8368\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_model(autoencoder, \"dataset/test/imgs\", \"dataset/test/test_annotation.txt\", threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8f5975",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
